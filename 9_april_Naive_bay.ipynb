{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7bb041c-9793-467b-b756-fffc43b353e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is Bayes' theorem?\n",
    "\n",
    "# Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "# Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "# Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "# Q6. Assignment:\n",
    "# You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive \n",
    "# Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of \n",
    "# each feature value for each class:\n",
    "\n",
    "# Class\t X1=1 X1=2 \tX1=3 \tX2=1 \tX2=2 \tX2=3\t X2=4\n",
    "\n",
    "#  A\t 3\t   3\t 4\t     4\t     3\t     3\t      3\n",
    "\n",
    "#  B\t 2\t   2\t 1\t     2\t     2\t     2\t      3\n",
    "\n",
    "# Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance \n",
    "# to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b8d04f-ac4a-4e23-886c-2958d6962f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80070d78-307b-45a6-b22f-f65e50e44c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes' theorem is a mathematical formula that provides a way to calculate conditional probabilities. \n",
    "# It describes the probability of an event based on prior knowledge or information. The theorem is named after Thomas Bayes, \n",
    "# an 18th-century British statistician and theologian who developed the idea.\n",
    "\n",
    "# The theorem states that the probability of a hypothesis (H) given some observed evidence (E) is proportional to the probability of the evidence given the hypothesis,\n",
    "# multiplied by the prior probability of the hypothesis:\n",
    "\n",
    "# P(H | E) = P(E | H) * P(H) / P(E)\n",
    "\n",
    "# where:\n",
    "\n",
    "# P(H | E) is the probability of the hypothesis H given the evidence E\n",
    "# P(E | H) is the probability of the evidence E given the hypothesis H\n",
    "# P(H) is the prior probability of the hypothesis H\n",
    "# P(E) is the prior probability of the evidence E\n",
    "\n",
    "# Bayes' theorem is a fundamental concept in probability theory and statistics, and it has applications in a wide range of fields, \n",
    "# including machine learning, data science, and artificial intelligence. It provides a way to update beliefs or hypotheses based on new evidence or data,\n",
    "# and to make informed decisions under uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f68f83f-e5b2-4bf1-882a-4a52969bfc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c29f53ae-b016-4e85-a4b0-1cbc09c91ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes' theorem can be mathematically expressed as:\n",
    "\n",
    "# P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "# where:\n",
    "\n",
    "# P(A|B) is the probability of event A given event B has occurred\n",
    "# P(B|A) is the probability of event B given event A has occurred\n",
    "# P(A) is the prior probability of event A occurring\n",
    "# P(B) is the prior probability of event B occurring\n",
    "\n",
    "# This formula can be interpreted as follows: the probability of event A given event B has occurred is proportional to the probability of \n",
    "# event B given that event A has occurred, multiplied by the prior probability of event A, divided by the prior probability of event B.\n",
    "\n",
    "# In other words, Bayes' theorem allows us to update our prior beliefs about the probability of an event based on new evidence. \n",
    "# It is widely used in fields such as statistics, machine learning, and artificial intelligence to make predictions and decisions under uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc526d3-37ab-4df9-91f0-45fb8515e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b392acc6-59ab-40d2-8485-6dfb75e5c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes' theorem is widely used in practice in a variety of fields, including statistics, machine learning, artificial intelligence, \n",
    "# and data science, to make predictions and decisions under uncertainty. Here are some common applications:\n",
    "\n",
    "# Spam filtering: Bayes' theorem can be used to filter spam emails by estimating the probability that an email is spam given certain keywords,\n",
    "# phrases, and patterns in the email.\n",
    "\n",
    "# Medical diagnosis: Bayes' theorem can be used to estimate the probability of a disease given certain symptoms, test results, and risk factors.\n",
    "\n",
    "# Image and speech recognition: Bayes' theorem can be used to estimate the probability that a certain image or speech signal belongs to a particular category, \n",
    "# such as faces or voices.\n",
    "\n",
    "# Financial modeling: Bayes' theorem can be used to estimate the probability of a stock or asset price movement given certain market indicators, news, and events.\n",
    "\n",
    "# Natural language processing: Bayes' theorem can be used to estimate the probability of a certain word or phrase given its context and surrounding words.\n",
    "\n",
    "# In practice, Bayes' theorem can be implemented using Bayesian inference techniques, which involve iteratively updating the prior probabilities based on\n",
    "# new data or evidence. These techniques are widely used in machine learning algorithms, such as Bayesian networks, Naive Bayes classifiers, and Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1770ca38-a27b-4f59-9305-d7fc9db77217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de4bafae-56a9-47a0-9450-784c2da8caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes' theorem and conditional probability are closely related concepts. In fact, Bayes' theorem can be seen as a way of calculating conditional probabilities.\n",
    "\n",
    "# Conditional probability is the probability of an event occurring given that another event has already occurred. \n",
    "# It is denoted as P(A | B), which is read as the probability of event A given event B. Bayes'\n",
    "# theorem provides a way to calculate this probability by reversing the order of the conditioning events.\n",
    "\n",
    "# Bayes' theorem states that the conditional probability of an event A given event B is proportional to the conditional probability of event B given event A, \n",
    "# multiplied by the prior probability of event A, and normalized by the marginal probability of event B. This can be written as:\n",
    "\n",
    "# P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "# In other words, Bayes' theorem tells us how to update our beliefs about the probability of event A given new information or evidence represented by event B.\n",
    "# It provides a way to incorporate new information into our prior beliefs and calculate the posterior probability of event A.\n",
    "\n",
    "# Conditional probability and Bayes' theorem are fundamental concepts in probability theory and statistics, and they have numerous applications in machine learning,\n",
    "# data science, and artificial intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1738e45d-cbc1-43ff-a398-294c4e79a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a53a54f6-d8ca-4426-b9e0-95ec96311c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Naive Bayes classifier is a family of probabilistic algorithms that are widely used in machine learning for classification tasks. \n",
    "# There are three main types of Naive Bayes classifiers:\n",
    "\n",
    "# Gaussian Naive Bayes: This classifier assumes that the features follow a Gaussian distribution. It is often used for continuous data.\n",
    "\n",
    "# Multinomial Naive Bayes: This classifier assumes that the features are multinomially distributed. It is often used for discrete data, such as text data.\n",
    "\n",
    "# Bernoulli Naive Bayes: This classifier assumes that the features are binary, i.e., they take on values of 0 or 1. It is often used for binary data,\n",
    "# such as presence or absence of certain features.\n",
    "\n",
    "# The choice of which type of Naive Bayes classifier to use for a given problem depends on several factors, such as the nature of the data, the number of features,\n",
    "# and the assumptions that can be made about the distribution of the data. Here are some guidelines that can be followed:\n",
    "\n",
    "# Gaussian Naive Bayes is appropriate when the features are continuous and have a normal distribution.\n",
    "\n",
    "# Multinomial Naive Bayes is appropriate when the features are discrete and have a multinomial distribution. This is commonly used for text classification problems.\n",
    "\n",
    "# Bernoulli Naive Bayes is appropriate when the features are binary, i.e., they take on values of 0 or 1.\n",
    "\n",
    "# It's important to note that the performance of the Naive Bayes classifier depends on the quality and relevance of the features used. \n",
    "# It is also important to properly preprocess the data, such as removing outliers, handling missing values, and normalizing the data if necessary.\n",
    "# It's a good idea to experiment with different types of Naive Bayes classifiers and see which one works best for a given problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17e120e2-d6da-4183-8192-4c66c6d76d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Assignment:\n",
    "# You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive \n",
    "# Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of \n",
    "# each feature value for each class:\n",
    "\n",
    "# Class\t X1=1 X1=2 \tX1=3 \tX2=1 \tX2=2 \tX2=3\t X2=4\n",
    "\n",
    "#  A\t 3\t   3\t 4\t     4\t     3\t     3\t      3\n",
    "\n",
    "#  B\t 2\t   2\t 1\t     2\t     2\t     2\t      3\n",
    "\n",
    "# Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance \n",
    "# to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d89354bf-0448-499a-88a8-6380324e7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict the class of the new instance with features X1=3 and X2=4 using Naive Bayes, \n",
    "# we first need to calculate the conditional probabilities of these features given each class, A and B.\n",
    "\n",
    "# For class A:\n",
    "# P(X1=3 | A) = 4/10 = 0.4\n",
    "# P(X2=4 | A) = 3/10 = 0.3\n",
    "\n",
    "# For class B:\n",
    "# P(X1=3 | B) = 1/9 ≈ 0.111\n",
    "# P(X2=4 | B) = 3/9 ≈ 0.333\n",
    "\n",
    "# Assuming equal prior probabilities for each class, i.e., P(A) = P(B) = 0.5, we can now calculate the posterior probabilities of each class using Bayes' theorem:\n",
    "\n",
    "# P(A | X1=3, X2=4) = P(X1=3 | A) * P(X2=4 | A) * P(A) / P(X1=3, X2=4)\n",
    "# = 0.4 * 0.3 * 0.5 / P(X1=3, X2=4)\n",
    "\n",
    "# P(B | X1=3, X2=4) = P(X1=3 | B) * P(X2=4 | B) * P(B) / P(X1=3, X2=4)\n",
    "# = 0.111 * 0.333 * 0.5 / P(X1=3, X2=4)\n",
    "\n",
    "# Since we are only interested in which class has a higher posterior probability, we can ignore the denominator, P(X1=3, X2=4), which is the same for both classes.\n",
    "# Therefore, we get:\n",
    "\n",
    "# P(A | X1=3, X2=4) = 0.06\n",
    "# P(B | X1=3, X2=4) ≈ 0.02\n",
    "\n",
    "# Therefore, Naive Bayes predicts that the new instance with features X1=3 and X2=4 belongs to class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6335e5a4-4ade-4738-a74b-2c4860a5eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the frequency table\n",
    "freq_table = {\n",
    "    'A': {'X1=1': 3, 'X1=2': 3, 'X1=3': 4, 'X2=1': 4, 'X2=2': 3, 'X2=3': 3, 'X2=4': 3},\n",
    "    'B': {'X1=1': 2, 'X1=2': 2, 'X1=3': 1, 'X2=1': 2, 'X2=2': 2, 'X2=3': 2, 'X2=4': 3}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1ff3785-5835-4fef-8fae-e413e271b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the conditional probabilities of the features given each class\n",
    "P_X1_3_given_A = freq_table['A']['X1=3'] / sum(freq_table['A'].values())\n",
    "P_X2_4_given_A = freq_table['A']['X2=4'] / sum(freq_table['A'].values())\n",
    "P_X1_3_given_B = freq_table['B']['X1=3'] / sum(freq_table['B'].values())\n",
    "P_X2_4_given_B = freq_table['B']['X2=4'] / sum(freq_table['B'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8f6044a-4dd7-4f1b-99be-6035b667381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the posterior probabilities of each class\n",
    "prior_prob = 0.5\n",
    "P_A_given_X1_3_X2_4 = P_X1_3_given_A * P_X2_4_given_A * prior_prob\n",
    "P_B_given_X1_3_X2_4 = P_X1_3_given_B * P_X2_4_given_B * prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5aea869f-5a5b-4643-bbf8-02488a298da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A | X1=3, X2=4) = 0.011342155009451795\n",
      "P(B | X1=3, X2=4) = 0.007653061224489795\n"
     ]
    }
   ],
   "source": [
    "# print the posterior probabilities\n",
    "print('P(A | X1=3, X2=4) =', P_A_given_X1_3_X2_4)\n",
    "print('P(B | X1=3, X2=4) =', P_B_given_X1_3_X2_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bf60d84-2966-473d-9db6-20cdacedfb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new instance belongs to class A\n"
     ]
    }
   ],
   "source": [
    "# predict the class of the new instance\n",
    "if P_A_given_X1_3_X2_4 > P_B_given_X1_3_X2_4:\n",
    "    print('The new instance belongs to class A')\n",
    "else:\n",
    "    print('The new instance belongs to class B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287779f-bb50-438c-a0de-fabdbeb7d5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
